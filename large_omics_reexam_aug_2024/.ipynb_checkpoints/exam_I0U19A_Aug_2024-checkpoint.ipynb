{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b81e7656",
   "metadata": {},
   "source": [
    "#  Exam I0U19A - Management of Large-Scale Omics Data\n",
    "\n",
    "Aug 2024\n",
    "\n",
    "**Note:** \n",
    "\n",
    "* The exam is open book and open internet. However the **use of any communication tool (phone, chat, mail, etc) is strictly forbidden!**\n",
    "* You are allowed to use Github during the exam - but do not post any comments.\n",
    "* You may use your phone ONLY for authentication purposes (to access toledo & the vcs)\n",
    "* For all questions - even if you cannot finish the question - please provide comments describing what you are plannning to do\n",
    "\n",
    "Exam will be evaluated based on this notebook & accompanying files uploaded to the Toledo Assignment. You will be expected to upload the following files:\n",
    "\n",
    "* This exam ipython notebook with your answers. (download using `Jupyter menu / File / Download`)\n",
    "* An HTML copy of above notebook (download using `Internet Browser menu / File / Save page as`)\n",
    "* Your new Snakemake file (`Snakefile`)\n",
    "* In general - **Make sure the plots you make are visible in this notebook before uploading to Toledo**\n",
    "   \n",
    "Please zip all files into one file with your r-number in the name: `rnumber.zip` - Note - Toledo does not allow the upload of .html files - so you must create an archive!\n",
    "\n",
    "**Note:** you will also be graded not only on the outcome of these exercises, but also on a number of criteria discussed during class, such as: writing resilient code; by running (simple) sanity checks; by properly documenting your code and decent visualizations.\n",
    "\n",
    "#### Preparation\n",
    "\n",
    "**Make sure you work on your exam in a dedicted work folder**\n",
    "\n",
    "Prior to starting the exam make sure you create a work folder:\n",
    "\n",
    "```\n",
    "mkdir -p $VSC_DATA/large_omics_reexam_aug_2024\n",
    "cd $VSC_DATA/large_omics_reexam_aug_2024\n",
    "```\n",
    "\n",
    "**Data required**\n",
    "\n",
    "Copy the data files to your work folder:\n",
    "\n",
    "```\n",
    "cd  $VSC_DATA/large_omics_reexam_aug_2024\n",
    "cp -r /staging/leuven/stg_00079/teaching/large_omics_reexam_aug_2024/* .\n",
    "```\n",
    "\n",
    "Among these files you will find the ipython exam notebook (`exam_I0U19A_Aug_2024.ipynb`). Continue working there.\n",
    "\n",
    "\n",
    "**Terminal/Conda**\n",
    "\n",
    "Do your (CPU intensive) command line work in a VSC interactive session. Please do not take too many scores or memory. This command was sufficient for me:\n",
    "\n",
    "```\n",
    "srun -n 1 -c 2 --mem 4G --time=4:00:00 -A lp_edu_large_omics -p interactive --cluster wice --pty bash -l\n",
    "```\n",
    "\n",
    "For **all** command line work (including snakemake) - make sure you use the correct conda environment by running the following in your shell:\n",
    "\n",
    "    export PATH=/lustre1/project/stg_00079/teaching/I0U19a_conda_2024/bin/:$PATH\n",
    "    \n",
    "You can check if you have the correct kernel loaded by running:\n",
    "\n",
    "    which python\n",
    "    \n",
    "Which should yield `/lustre1/project/stg_00079/teaching/I0U19a_conda_2024/bin/python`\n",
    "\n",
    "\n",
    "**Jupyter**\n",
    "\n",
    "Ondemand settings (as used in class):\n",
    "\n",
    "* cluster: Wice\n",
    "* Account: lp_edu_large_omics\n",
    "* Partition: Batch\n",
    "* Number of hours: Duration of the exam +1hr\n",
    "* Number of cores: 1\n",
    "* Required memory per core: 3000 \n",
    "* Number of nodes: 1\n",
    "* Number of GPU's: 0\n",
    "\n",
    "Ensure you use the correct kernel for the jupyter work! You can confirm you have the correct kernel by running (in python):\n",
    "\n",
    "    import sys\n",
    "    sys.executable\n",
    "    \n",
    "Which should yield `/lustre1/project/stg_00079/teaching/I0U19a_conda_2024/bin/python`\n",
    "\n",
    "If not, please check the Toledo posts.\n",
    "\n",
    "---\n",
    "\n",
    "**After copying the data to your work folder, you will find a notebook called `exam_I0U19A_Aug_2024.ipynb` in the `$VSC_DATA/large_omics_reexam_aug_2024` folder - continue your work there.**\n",
    "\n",
    "---\n",
    "\n",
    "**Best of luck,**\n",
    "Mark\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97e18936",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/lustre1/project/stg_00079/teaching/I0U19a_conda_2024/bin/python'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check your kernel\n",
    "import sys\n",
    "sys.executable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9860440b",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac27519f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import vcfpy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94bf96a2-8412-4b74-b1f6-30b96c6d9000",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Question 1 - Snakemake\n",
    "\n",
    "In your exam folder you wil a snakemake folder containing the workflow definition (`snakemake/Snakefile`) and the tumor/control fastq data. This Snakefile is the same Snakefile we created during the course. The workflow has not been executed yet.\n",
    "\n",
    "The objective of this question is to expand the Snakemake file to further annotate the final snpEFF annotated VCF file using PhastCons conservation scores.\n",
    "\n",
    "snpEff as a tool is powerful - but only predicts coding effects. We are also potentially interested in non-coding SNPs. One method to identify potentially interesting non-coding SNPs is by looking at conservation. Regions that are evolutionary conserved are more likely to have a function. So non-coding SNPs in conserved regions are of more interest. We will be using [Phast/PhastCons](http://compgen.cshl.edu/phast/) to find such SNPs.\n",
    "\n",
    "I already downloaded the database (for chr9 only) and a file indicating genome sizes. These files can be found in `/staging/leuven/stg_00079/teaching/phastcons`. \n",
    "\n",
    "We will be using `snpEff`'s sister tool `snpSift` to annotate our vcf file with the `phastCons` scores. `snpSift` is installed in our conda environment. I already added the location of the jar file to the Snakemake file.\n",
    "\n",
    "The goal of this exercise is to extend the Snakemake workflow to automatically annotate  our final vcf file (`snakemake/050.snpeff/snps.annotated.vcf`) with the PhastCons scores. Note, you must create a new rule, and this rule must be automatically executed when running Snakemake without specifying a target.\n",
    "\n",
    "Second goal is to create a filtered down VCF file of only those variants that have (at least one) LOW/MODERATE/HIGH impact and a phastcons score > 0.5.\n",
    "\n",
    "**To prove you did this - please find and copy - from the resulting vcf file - the line containing the SNP on chromosome 9, position 129702113 in the cell below**\n",
    "\n",
    "(do not use my provided vcf file!)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6061bc92-d0e1-482e-ba00-6ace7448dd50",
   "metadata": {},
   "source": [
    "```\n",
    "**copy past the requested vcf line (from chr9, position 129702113) here**\n",
    "```\n",
    "grep -w \"129702113\" 060.phastCons/snps.phastcons.vcf\n",
    "\n",
    "chr9\t129702113\t.\tG\tA\t24.0638\t.\tDP=2;VDB=0.38;SGB=0.0985265;MQSBZ=-1;MQ0F=0;AC=2;AN=2;DP4=0,0,1,1;MQ=35;ANN=A|intron_variant|MODIFIER|PRRX2|ENSG00000167157|transcript|ENST00000372469.6|protein_coding|1/3|c.260-17118G>A||||||;PhastCons=0.006\tGT:PL\t./.:0,0,0\t1/1:51,6,0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a32f02-c824-4b4b-9ee5-e37ccd5174d7",
   "metadata": {},
   "source": [
    "**Note**:\n",
    "\n",
    " * `snpSift` is available in our conda environment\n",
    " * The phastCons data is in `/lustre1/project/stg_00079/teaching/phastcons`\n",
    " * You must add at least **one new [rule](https://snakemake.readthedocs.io/en/stable/snakefiles/rules.html)** to the `Snakefile`.\n",
    " * Make sure the PhastCons annotated vcf file ends up in a dedicated subfolder.\n",
    " * Create another new rule creating a  **filtered phastcons vcf** file, containing ONLY those snps that have (at least one) LOW/MODERATE/HIGH impact (excluding variants that have only MODIFIER impacts)  **and** have a phastcons score of > 0.5. How many variants are in the this filtered vcf file (please fill in the number in the cell below).\n",
    " * Ensure the both new rules get executed automatically when running Snakemake without specifying a rule.\n",
    " * Make sure your final `Snakefile` is part of the Toledo assignment upload.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abbbf94f-a493-4a1f-b337-ff54b13e29a8",
   "metadata": {},
   "source": [
    "**How many SNPs are in the filtered VCF file?:**\n",
    "92 SNPs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a357f503-6a3a-42a6-a831-2252650353af",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Question 2 - Extending the SNP database\n",
    "\n",
    "You will find a reference notebook as we used in class (`ParseVCF.ipynb`) in this folder. The database it created `snps.sqlite` which also in the data folder.\n",
    "\n",
    "The goal is to include the phastCons scores from the VCF file into the database so that we can use this for visualizations.\n",
    "\n",
    "**Note:**\n",
    "\n",
    "* Please use the `ParseVCF.ipynb` notebook only for reference. Write all extra code you need below this cell.\n",
    "* Continue your work using the database included (`snps.sqlite`)\n",
    "* Create a **new** table with the phastcons scores (and snp identifier)\n",
    "* Make sure you sanity check your data. Are all scores between 0 and 1? Do all SNPs from the input file get a PhastCons score? What do you do with the SNPs that do not? Discuss your choices.\n",
    "* To be sure you are not dependent on the last exercise - I provide a vcf file with the phastCons scores called in `vcf_files/snps.phastcons.vcf`. For safety I also have the snpEff annotated vcf file available (`vcf_files/snps.annotated.vcf` - which you should not use to answer the question above!)\n",
    "* Test it worked by writing a SQL statement that counts the number of variants with a LOW, MODERATE or HIGH impact and a phastcons score > 0.5. Make sure the answer is readable in a cell below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e61b5ee4",
   "metadata": {},
   "source": [
    "The phastCon function from snpSIFT scores SNP's based on a database of experimental findings. SNP's not in the database will not be scored, however it would be innappropriate to mark them 0 as a snp without a phastCon score could have any level of conservation, it simply has not been noted in the database. Therefore SNP's without conservation scores are not included in the phastCon table.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f5a969f-efa4-4b51-902a-381edbc264ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dbfile      : snps.sqlite\n",
      "db          : <sqlite3.Connection object at 0x14eb90a9fd40>\n",
      "vcf         : ./snakemake/060.phastCons/snps.phastcons.vcf\n",
      "vcf exist?  : True\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import sqlite3\n",
    "\n",
    "import pandas as pd\n",
    "import vcfpy\n",
    "\n",
    "# Define the source file and the destination file\n",
    "db_file = 'snps.sqlite'\n",
    "\n",
    "db = sqlite3.connect(db_file)\n",
    "\n",
    "vcf = \"./snakemake/060.phastCons/snps.phastcons.vcf\"\n",
    "\n",
    "print(f\"dbfile      : {db_file}\")\n",
    "print(f\"db          : {db}\")\n",
    "print(f\"vcf         : {vcf}\")\n",
    "print(f\"vcf exist?  : {Path(vcf).exists()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9f8eec44-f4c4-4e16-b864-b63313f29c87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1180\n"
     ]
    },
    {
     "ename": "DatabaseError",
     "evalue": "Execution failed on sql 'DROP TABLE \"snp_phastCon\"': database is locked",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "File \u001b[0;32m/lustre1/project/stg_00079/teaching/I0U19a_conda_2024/lib/python3.10/site-packages/pandas/io/sql.py:2672\u001b[0m, in \u001b[0;36mSQLiteDatabase.execute\u001b[0;34m(self, sql, params)\u001b[0m\n\u001b[1;32m   2671\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 2672\u001b[0m     \u001b[43mcur\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43msql\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2673\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cur\n",
      "\u001b[0;31mOperationalError\u001b[0m: database is locked",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mDatabaseError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 38\u001b[0m\n\u001b[1;32m     36\u001b[0m phastCon_records \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame\u001b[38;5;241m.\u001b[39mfrom_records(phastCon_records)\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m#save to db\u001b[39;00m\n\u001b[0;32m---> 38\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mphastCon records :\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[43mphastCon_records\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_sql\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msnp_phastCon\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mif_exists\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mreplace\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m)\n\u001b[1;32m     40\u001b[0m phastCon_records\u001b[38;5;241m.\u001b[39mhead()\n",
      "File \u001b[0;32m/lustre1/project/stg_00079/teaching/I0U19a_conda_2024/lib/python3.10/site-packages/pandas/util/_decorators.py:333\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    328\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    329\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    330\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    331\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    332\u001b[0m     )\n\u001b[0;32m--> 333\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/lustre1/project/stg_00079/teaching/I0U19a_conda_2024/lib/python3.10/site-packages/pandas/core/generic.py:3084\u001b[0m, in \u001b[0;36mNDFrame.to_sql\u001b[0;34m(self, name, con, schema, if_exists, index, index_label, chunksize, dtype, method)\u001b[0m\n\u001b[1;32m   2886\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2887\u001b[0m \u001b[38;5;124;03mWrite records stored in a DataFrame to a SQL database.\u001b[39;00m\n\u001b[1;32m   2888\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3080\u001b[0m \u001b[38;5;124;03m[(1,), (None,), (2,)]\u001b[39;00m\n\u001b[1;32m   3081\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m  \u001b[38;5;66;03m# noqa: E501\u001b[39;00m\n\u001b[1;32m   3082\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m sql\n\u001b[0;32m-> 3084\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msql\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_sql\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3085\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3086\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3087\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3088\u001b[0m \u001b[43m    \u001b[49m\u001b[43mschema\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3089\u001b[0m \u001b[43m    \u001b[49m\u001b[43mif_exists\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mif_exists\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3090\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3091\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3092\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3093\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3094\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3095\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/lustre1/project/stg_00079/teaching/I0U19a_conda_2024/lib/python3.10/site-packages/pandas/io/sql.py:842\u001b[0m, in \u001b[0;36mto_sql\u001b[0;34m(frame, name, con, schema, if_exists, index, index_label, chunksize, dtype, method, engine, **engine_kwargs)\u001b[0m\n\u001b[1;32m    837\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[1;32m    838\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mframe\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m argument should be either a Series or a DataFrame\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    839\u001b[0m     )\n\u001b[1;32m    841\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m pandasSQL_builder(con, schema\u001b[38;5;241m=\u001b[39mschema, need_transaction\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m pandas_sql:\n\u001b[0;32m--> 842\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpandas_sql\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_sql\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    843\u001b[0m \u001b[43m        \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    844\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    845\u001b[0m \u001b[43m        \u001b[49m\u001b[43mif_exists\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mif_exists\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    846\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    847\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    848\u001b[0m \u001b[43m        \u001b[49m\u001b[43mschema\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    849\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    850\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    851\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    852\u001b[0m \u001b[43m        \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    853\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    854\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/lustre1/project/stg_00079/teaching/I0U19a_conda_2024/lib/python3.10/site-packages/pandas/io/sql.py:2848\u001b[0m, in \u001b[0;36mSQLiteDatabase.to_sql\u001b[0;34m(self, frame, name, if_exists, index, index_label, schema, chunksize, dtype, method, engine, **engine_kwargs)\u001b[0m\n\u001b[1;32m   2837\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcol\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmy_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) not a string\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   2839\u001b[0m table \u001b[38;5;241m=\u001b[39m SQLiteTable(\n\u001b[1;32m   2840\u001b[0m     name,\n\u001b[1;32m   2841\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2846\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[1;32m   2847\u001b[0m )\n\u001b[0;32m-> 2848\u001b[0m \u001b[43mtable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2849\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m table\u001b[38;5;241m.\u001b[39minsert(chunksize, method)\n",
      "File \u001b[0;32m/lustre1/project/stg_00079/teaching/I0U19a_conda_2024/lib/python3.10/site-packages/pandas/io/sql.py:988\u001b[0m, in \u001b[0;36mSQLTable.create\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    986\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTable \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m already exists.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    987\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mif_exists \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreplace\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 988\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpd_sql\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop_table\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mschema\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    989\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_execute_create()\n\u001b[1;32m    990\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mif_exists \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mappend\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m/lustre1/project/stg_00079/teaching/I0U19a_conda_2024/lib/python3.10/site-packages/pandas/io/sql.py:2870\u001b[0m, in \u001b[0;36mSQLiteDatabase.drop_table\u001b[0;34m(self, name, schema)\u001b[0m\n\u001b[1;32m   2868\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdrop_table\u001b[39m(\u001b[38;5;28mself\u001b[39m, name: \u001b[38;5;28mstr\u001b[39m, schema: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2869\u001b[0m     drop_sql \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDROP TABLE \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_get_valid_sqlite_name(name)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 2870\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdrop_sql\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/lustre1/project/stg_00079/teaching/I0U19a_conda_2024/lib/python3.10/site-packages/pandas/io/sql.py:2684\u001b[0m, in \u001b[0;36mSQLiteDatabase.execute\u001b[0;34m(self, sql, params)\u001b[0m\n\u001b[1;32m   2681\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ex \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01minner_exc\u001b[39;00m\n\u001b[1;32m   2683\u001b[0m ex \u001b[38;5;241m=\u001b[39m DatabaseError(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExecution failed on sql \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msql\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 2684\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m ex \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n",
      "\u001b[0;31mDatabaseError\u001b[0m: Execution failed on sql 'DROP TABLE \"snp_phastCon\"': database is locked"
     ]
    }
   ],
   "source": [
    "\n",
    "phastCon_records = []\n",
    "j = 0\n",
    "\n",
    "#open the vcf iterator:\n",
    "reader = vcfpy.Reader.from_path(vcf)\n",
    "\n",
    "for i, record in enumerate(reader):\n",
    "    j += 1\n",
    "    \n",
    "    assert len(record.ALT) == 1 \n",
    "    alt = record.ALT[0]\n",
    "    \n",
    "    # compose a SNP name for joins later on\n",
    "    snp_name = f\"{record.CHROM}:{record.POS}:{record.REF}:{alt.value}\"\n",
    "    \n",
    "    # Retrieve the PhastCons conservation score from the INFO field\n",
    "    phastCon_j = record.INFO.get('PhastCons', None)\n",
    "\n",
    "    # not all snps get a phastCon score. scoring is based on a database of experimental findings\n",
    "    # a snp without a phastCon score could have any level of conservation\n",
    "    # it is most appropriate to mark it none and not include SNP's without phastcon in the phastcon records table        \n",
    "    if phastCon_j is not None:\n",
    "        if phastCon_j < 0 or phastCon_j > 1:\n",
    "            print('Error: phastCon', snp_name, 'outside appropriate range')\n",
    "        else: #only store appropriate values\n",
    "            # Store SNP record and gene information\n",
    "            phastCon_records.append(\n",
    "                dict(snp=snp_name,\n",
    "                    phastCon=phastCon_j)\n",
    "        )\n",
    "\n",
    "\n",
    "print(len(phastCon_records))\n",
    "db.close()\n",
    "\n",
    "#convert lists of dicts to a DataFrame\n",
    "phastCon_records = pd.DataFrame.from_records(phastCon_records)\n",
    "#save to db\n",
    "db = sqlite3.connect(db_file)\n",
    "print('phastCon records :', phastCon_records.to_sql('snp_phastCon', db, if_exists='replace', index=False))\n",
    "db.close()\n",
    "\n",
    "phastCon_records.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ba721536-c3e2-465b-baf7-d6af21be9812",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of variants with a LOW, MODERATE or HIGH impact and a phastcons score > 0.5 =  92\n"
     ]
    }
   ],
   "source": [
    "#get first cell of table Count\n",
    "#select from snp_phastCon where phastCon greater than 0.5 \n",
    "# and \n",
    "#the join on snp_effect has impact LOW/MODERATE/HIGH\n",
    "print('number of variants with a LOW, MODERATE or HIGH impact and a phastcons score > 0.5 = ',pd.read_sql(\n",
    "    \"\"\"\n",
    "    SELECT COUNT(*) AS row_count\n",
    "    FROM (\n",
    "        SELECT DISTINCT\n",
    "            snp_phastCon.snp,\n",
    "            snp_phastCon.phastCon\n",
    "        FROM snp_phastCon\n",
    "        JOIN snp_effect ON snp_phastCon.snp = snp_effect.snp\n",
    "        WHERE snp_phastCon.phastCon > 0.5\n",
    "        AND snp_effect.impact IN ('LOW', 'MODERATE', 'HIGH')\n",
    "    ) AS subquery\n",
    "    \"\"\", db).iloc[0,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf4c9f3c",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Question 3 - Visualization\n",
    "\n",
    "Given the the database you just generated - can you investigate if HIGH impact variants have a different distribution of phastcons scores that MODIFIER variants? \n",
    "\n",
    "**Note:**\n",
    " * Argue what the biological reason/impact might be\n",
    " * Defend your choice of visualization.\n",
    " * Argue your process & thinking while exploring the data.\n",
    " * **Make a plot!** (you do not need to do statistics).\n",
    " * Make sure your plot is visible in this notebook prior to uploading it to Toledo.\n",
    " * **Discuss your interpretation of the plot, doublecheck your conclusions, if required adapt your visualization**\n",
    " * If you did not manage Question 2 you can request a copy of the database from me.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a7cf91",
   "metadata": {},
   "source": [
    "HIGH impact SNP's should have a higher average conservation score than the MODIFIER variants. The highly conserved regions are vital to the cell so you would expect that they have higher impact if a mutation occurs. The MODIFIER impact label means that the variant is not believed to directly affect protein expression. Instead these have negligible effects, affect regulation, or poorly understood effects. Therefore it is expected that MODIFIER snp's will closely match the normal distribution for conservation scores as they can occur in highly conserved regulatory regions, low impact repeated regions etc.\n",
    "\n",
    "However, the phastCon dataset does not have scores for many of the variants so there is very little data on HIGH impact conservation scores. The sample size is insufficient to make any statistically significant observation on this data. \n",
    "\n",
    "I chose a violin plot to display the data as it visualises the basic summary statistics but also represents sample density and allows for multimodal distribution.\n",
    "\n",
    "MODERATE and LOW impact samples were also plotted. Since there is more data for those impact types I believe they are useful to establish the trend that conservation skews higher as impact factor rises. As expected the MODIFIER variants occur in both low and high conservation regions with a bias to low."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0407ba51-21b7-4239-a743-3a378531f88f",
   "metadata": {},
   "outputs": [
    {
     "ename": "OperationalError",
     "evalue": "database is locked",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Create a view for easier access to the joined data\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mdb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mDROP VIEW IF EXISTS VisualisationData\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m db\u001b[38;5;241m.\u001b[39mexecute(\n\u001b[1;32m      5\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;124;03m    CREATE VIEW VisualisationData AS\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;124;03m        snp_effect ON snp_phastCon.snp = snp_effect.snp;\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m#save as a dataframe\u001b[39;00m\n",
      "\u001b[0;31mOperationalError\u001b[0m: database is locked"
     ]
    }
   ],
   "source": [
    "# Create a view for easier access to the joined data\n",
    "db.execute(\"DROP VIEW IF EXISTS VisualisationData\")\n",
    "\n",
    "db.execute(\n",
    "    \"\"\"\n",
    "    CREATE VIEW VisualisationData AS\n",
    "    SELECT\n",
    "        snp_phastCon.snp,\n",
    "        snp_phastCon.phastCon,\n",
    "        snp_effect.impact\n",
    "    FROM \n",
    "        snp_phastCon\n",
    "    JOIN \n",
    "        snp_effect ON snp_phastCon.snp = snp_effect.snp;\n",
    "    \"\"\")\n",
    "\n",
    "#save as a dataframe\n",
    "VisualData = pd.read_sql(\"SELECT * FROM VisualisationData\", db)\n",
    "#display the view\n",
    "print(pd.read_sql(\"SELECT * FROM VisualisationData\", db))\n",
    "\n",
    "print('\\nCount by impact')\n",
    "print(pd.read_sql(\n",
    "    \"\"\"\n",
    "    SELECT \n",
    "        impact,\n",
    "        COUNT(*) AS count\n",
    "    FROM \n",
    "        VisualisationData\n",
    "    GROUP BY \n",
    "        impact;\n",
    "\n",
    "    \"\"\", db))\n",
    "\n",
    "print('\\nHIGH impact phastCons')\n",
    "print(pd.read_sql(\n",
    "    \"\"\"\n",
    "    SELECT * FROM VisualisationData WHERE impact = 'HIGH';\n",
    "    \"\"\", db))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d785a7a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the desired order of impact categories\n",
    "impact_order = ['LOW', 'MODERATE', 'HIGH', 'MODIFIER']\n",
    "\n",
    "# Create the violin plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.violinplot(x='impact', y='phastCon',order=impact_order, data=VisualData)\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Impact')\n",
    "plt.ylabel('PhastCon Score')\n",
    "plt.ylim(0,1)\n",
    "plt.title('Violin Plot of PhastCon Scores by Impact Type')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "large_omics_2024",
   "language": "python",
   "name": "large_omics_2024"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
